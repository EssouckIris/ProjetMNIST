{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f7297bf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7bf5b5a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Chargement du jeu de donn es MNIST\n",
    "(x_train, y_train), (x_test, y_test) = keras.datasets.mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b0c9fd9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = x_train.astype(\"float32\") / 255.0\n",
    "x_test = x_test.astype(\"float32\") / 255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f893e1b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = x_train.reshape(60000, 784)\n",
    "x_test = x_test.reshape(10000, 784)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8edb8979",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.Sequential([\n",
    "keras.layers.Dense(512, activation='relu', input_shape=(784,)),\n",
    "keras.layers.Dropout(0.2),\n",
    "keras.layers.Dense(10, activation='softmax')\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "21f6c4ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(\n",
    "optimizer='adam',\n",
    "loss='sparse_categorical_crossentropy',\n",
    "metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "74b9886e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "422/422 [==============================] - 4s 9ms/step - loss: 0.3076 - accuracy: 0.9112 - val_loss: 0.1264 - val_accuracy: 0.9680\n",
      "Epoch 2/5\n",
      "422/422 [==============================] - 4s 9ms/step - loss: 0.1318 - accuracy: 0.9614 - val_loss: 0.0965 - val_accuracy: 0.9732\n",
      "Epoch 3/5\n",
      "422/422 [==============================] - 4s 9ms/step - loss: 0.0902 - accuracy: 0.9729 - val_loss: 0.0789 - val_accuracy: 0.9765\n",
      "Epoch 4/5\n",
      "422/422 [==============================] - 4s 9ms/step - loss: 0.0706 - accuracy: 0.9784 - val_loss: 0.0696 - val_accuracy: 0.9795\n",
      "Epoch 5/5\n",
      "422/422 [==============================] - 4s 9ms/step - loss: 0.0549 - accuracy: 0.9833 - val_loss: 0.0669 - val_accuracy: 0.9808\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(\n",
    "  x_train,\n",
    "  y_train,\n",
    "  epochs=5,\n",
    "  batch_size=128,\n",
    "  validation_split=0.1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b99ce45e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 1s 3ms/step - loss: 0.0751 - accuracy: 0.9766\n",
      "Pr cision sur les donnees de test: 0.9766\n"
     ]
    }
   ],
   "source": [
    "test_loss, test_acc = model.evaluate(x_test, y_test)\n",
    "print(f\"Pr cision sur les donnees de test: {test_acc:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "64da4d94",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Mod le sauvegard sous mnist_model_t.h5\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#Sauvegarde du modele\n",
    "model.save(\"mnist_model_t.h5\")\n",
    "print(\" Mod le sauvegard sous mnist_model_t.h5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b7ae567",
   "metadata": {},
   "source": [
    "### UTILITE DES COUCHES DENSE ET DROPOUT\n",
    "##### Dense\n",
    "Chaque neurone est relie a tous les neurones de la couche precedente, elle permet de prendre la decision finale\n",
    "##### Dropout\n",
    "elle sert a la regularisation pour eviter le surapprentissage"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb48294b",
   "metadata": {},
   "source": [
    "# Adam amelioration du SGD simple\n",
    "adam combine deux optimisations majeur :\n",
    "- le momentum\n",
    "- le RMSProp\n",
    "il adapte automatiquement la vitesse de chaque parametre et garde la direction moyenne du gradient, donc il adapte automatiquement le learning rate de chaque poid, alors qu'avec le SGD si le learning rate etait trop grand l'entrainement sautait autour du minimum et n'arrivais jamais a converger.chaque neurone etait mis a jour avec la meme intensitememe si certains convergent plus vite que d'autres"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4d4bdfa",
   "metadata": {},
   "source": [
    "# Les concepts de \"vectorisation\" et de \"calculs par lots\"\n",
    "\n",
    "#### Vectorisation\n",
    "chaque image est transformee en vecteur de talle 784, toutes les images sont regroupees dans une grande matrice\n",
    "\n",
    "#### Calculs par lot\n",
    "c'est lorsqu'on utilise le batch_size\n",
    "batch_size=128\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "561e9496",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
